# Quick Start Guide - n8n AI Agents

Schnelleinstieg in 15 Minuten!

## Schritt 1: MCP Server Setup (5 Minuten)

### Installation

```bash
cd n8n-ai-agents/mcp-server
npm install
```

### Test den Server

```bash
npm start
```

Du solltest sehen: `n8n AI Agents MCP Server running on stdio`

DrÃ¼cke `Ctrl+C` um zu stoppen.

### Claude Code Konfiguration

FÃ¼ge den Server zu deiner Claude Code Config hinzu:

**Linux:** `~/.config/claude-code/config.json`
**macOS:** `~/Library/Application Support/Claude Code/config.json`

```json
{
  "mcpServers": {
    "n8n-ai-agents": {
      "command": "node",
      "args": ["/ABSOLUTER/PFAD/ZU/n8n-ai-agents/mcp-server/server.js"]
    }
  }
}
```

**Wichtig:** Ersetze den Pfad mit deinem tatsÃ¤chlichen absoluten Pfad!

Finde deinen Pfad mit:
```bash
cd n8n-ai-agents/mcp-server
pwd
```

## Schritt 2: Lokales LLM Setup (5 Minuten)

### Option A: Ollama (Empfohlen)

```bash
# Installation
curl -fsSL https://ollama.com/install.sh | sh

# Nemotron Nano herunterladen und starten
ollama pull nemotron-nano:9b
ollama serve
```

Test ob es lÃ¤uft:
```bash
curl http://localhost:11434/api/generate -d '{
  "model": "nemotron-nano:9b",
  "prompt": "Hello",
  "stream": false
}'
```

### Option B: Alternatives Modell

Falls Nemotron Nano nicht verfÃ¼gbar:
```bash
# Alternatives kleines Modell
ollama pull gemma2:9b
# oder
ollama pull llama3.2:3b
```

## Schritt 3: n8n Workflow erstellen (5 Minuten)

### Workflow in n8n importieren

1. Ã–ffne n8n: `http://localhost:5678`
2. Klicke auf "+" â†’ "Import from File" oder "Import from URL"
3. Nutze einen der Templates aus `/workflows/`

### Oder: Manuell mit Claude Code erstellen

```bash
cd n8n-ai-agents
claude-code
```

Dann im Chat:
```
Erstelle mir einen n8n Workflow fÃ¼r Entity Extraction der:
- OpenAI GPT-4o-mini nutzt
- Lokales LLM als Fallback hat
- Robuste Input/Output Validation hat
- Test-Daten aus test-data/sample-tests.json nutzt
```

Claude Code wird automatisch:
1. Den MCP Server nutzen fÃ¼r Best Practices
2. Ein Template generieren
3. Anpassen an deine Anforderungen
4. Als JSON in `/workflows/` speichern

## Schritt 4: Erster Test

### API Keys setzen

In n8n:
1. Gehe zu **Settings** â†’ **Credentials**
2. FÃ¼ge **OpenAI API** Credential hinzu
3. Trage deinen API Key ein

### Workflow testen

1. Importiere `workflows/entity-extraction-example.json`
2. Ã–ffne den Workflow
3. Klicke auf **"Execute Workflow"**
4. PrÃ¼fe die Ergebnisse

### Mit Test-Daten

Wenn du den Batch-Test Workflow verwendest:
1. Passe den "Load Test Cases" Node an
2. Lade `test-data/sample-tests.json`
3. FÃ¼hre aus und vergleiche Ergebnisse

## NÃ¤chste Schritte

### Experimentiere mit Prompts

```bash
claude-code
```

```
Gib mir 3 verschiedene Prompt-Varianten fÃ¼r Entity Extraction
mit einem 9B Modell. Teste sie mit den Beispieldaten.
```

### Vergleiche Modelle

Nutze den `llm-comparison` Template:
```
Erstelle einen Workflow der OpenAI, lokales LLM und 
Anthropic Claude parallel testet und Ergebnisse vergleicht.
```

### Optimiere fÃ¼r Robustheit

```
Analysiere meinen Workflow in workflows/my-workflow.json
und schlage Verbesserungen vor fÃ¼r Robustheit.
```

## Troubleshooting

### MCP Server nicht gefunden

```bash
# PrÃ¼fe Config
cat ~/.config/claude-code/config.json

# Teste Server manuell
cd n8n-ai-agents/mcp-server
node server.js
```

### Lokales LLM antwortet nicht

```bash
# PrÃ¼fe ob Ollama lÃ¤uft
curl http://localhost:11434/api/tags

# Neu starten
ollama serve
```

### n8n findet Credentials nicht

1. Gehe zu **Settings** â†’ **Credentials**
2. Erstelle neue Credential
3. WÃ¤hle den Credential-Typ im Node aus

## Tipps fÃ¼r Rapid Prototyping

### 1. Start klein
Beginne mit einem einfachen Task (z.B. nur Entity Extraction)

### 2. Validiere zuerst
FÃ¼ge Input/Output Validation hinzu bevor du LLMs testest

### 3. Iteriere schnell
```bash
# In Claude Code
"Ã„ndere den Prompt zu: [deine Ã„nderung]"
"Teste mit test-data/sample-tests.json"
"Vergleiche mit vorheriger Version"
```

### 4. Dokumentiere Ergebnisse
Speichere Testergebnisse in `/results/`:
```json
{
  "test_run": "2026-02-04_15-30",
  "prompt_version": "v1.2",
  "model": "gpt-4o-mini",
  "results": [...]
}
```

## Hilfreiche Commands

```bash
# Claude Code starten
claude-code

# n8n starten (falls nicht lÃ¤uft)
n8n start

# Ollama Model Liste
ollama list

# Neue Test-Daten hinzufÃ¼gen
echo '{"id": "test_011", "text": "...", "expected": {...}}' >> test-data/sample-tests.json
```

## Ressourcen

- **Dokumentation:** `docs/n8n-agent-guide.md`
- **MCP Server README:** `mcp-server/README.md`
- **Test-Daten:** `test-data/sample-tests.json`
- **Beispiel Workflows:** `workflows/`

## Support

Bei Problemen:
1. PrÃ¼fe die Logs in n8n
2. Teste MCP Server manuell
3. Verifiziere Ollama lÃ¤uft
4. PrÃ¼fe API Keys in n8n

**Viel Erfolg beim Prototyping! ðŸš€**
